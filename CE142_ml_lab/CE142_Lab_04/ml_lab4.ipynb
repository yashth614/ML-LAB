{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sfnchTGpnJxA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70]], dtype='float32')"
      ],
      "metadata": {
        "id": "_uUIXcRhnRXL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119]], dtype='float32')"
      ],
      "metadata": {
        "id": "DrZFmaCKnUGz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg339-s0nWo1",
        "outputId": "75d5ee9e-831c-45bd-b921-8fc0837ebd75"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.randn(2, 3, requires_grad=True)\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zH61QJ2LnaPA",
        "outputId": "e7b18aee-f2c4-466d-937c-1a567206efbe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5873,  0.1307,  1.0837],\n",
            "        [ 1.1671, -0.0845,  0.6151]], requires_grad=True)\n",
            "tensor([-0.4552, -0.6961], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model(x):\n",
        "    return x @ w.t() + b"
      ],
      "metadata": {
        "id": "nsMmGqvLnfLS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ5ewMuinjZ-",
        "outputId": "88f280a4-05aa-45b9-deb5-5e5068d785d4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 97.7760, 105.2888],\n",
            "        [133.8504, 137.4388],\n",
            "        [131.0122, 125.1908],\n",
            "        [105.1688, 137.4737],\n",
            "        [128.4773, 114.7765]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgZwNNWCnmAX",
        "outputId": "ab63d557-4dfb-49f4-df47-c86f06fe2ba3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(t1, t2):\n",
        "    diff = t1 - t2\n",
        "    return torch.sum(diff * diff) / diff.numel()"
      ],
      "metadata": {
        "id": "DKuAFqYMnpcp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXKqiChvnuDD",
        "outputId": "0fc3442d-ef64-47a4-8743-5a780334fb53"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2499.5710, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "id": "eS3cko4jnw8a"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w)\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfKzg9m8nz0Y",
        "outputId": "c1fa1061-d4cb-4f24-c284-cfcadbcd1127"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5873,  0.1307,  1.0837],\n",
            "        [ 1.1671, -0.0845,  0.6151]], requires_grad=True)\n",
            "tensor([[3829.0498, 3016.3086, 2147.2322],\n",
            "        [3033.9011, 1687.8875, 1363.6892]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdAzFTnNn2T1",
        "outputId": "197db21a-55b8-4b73-a924-c2ff57fce1d6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOLAL33On4_v",
        "outputId": "3a35aad9-e024-4b87-efbe-96a4e2efd87d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 97.7760, 105.2888],\n",
            "        [133.8504, 137.4388],\n",
            "        [131.0122, 125.1908],\n",
            "        [105.1688, 137.4737],\n",
            "        [128.4773, 114.7765]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncPJkRSBn-QR",
        "outputId": "2295bbde-2ede-4ac3-b389-4faab711284c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2499.5710, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkgVFMmwoDeg",
        "outputId": "aecf662f-3db8-4c20-9a2b-2d87e16c2686"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3829.0498, 3016.3086, 2147.2322],\n",
            "        [3033.9011, 1687.8875, 1363.6892]])\n",
            "tensor([43.0569, 32.0337])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()"
      ],
      "metadata": {
        "id": "CDKRcOecoGLA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGHjchvhoJxL",
        "outputId": "90eff507-1b24-4459-bcc3-07af275ec7fd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5490,  0.1006,  1.0622],\n",
            "        [ 1.1368, -0.1014,  0.6015]], requires_grad=True)\n",
            "tensor([-0.4557, -0.6965], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs)\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uoo8htaRoRqG",
        "outputId": "6d047c9a-aa7c-4af7-cda1-bfd750a7c180"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2113.0884, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l1=[]\n",
        "for i in range(1000):\n",
        "    preds = model(inputs)\n",
        "    loss = mse(preds, targets)\n",
        "    l1.append(loss.cpu().detach().numpy())\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        w -= w.grad * 1e-5\n",
        "        b -= b.grad * 1e-5\n",
        "        w.grad.zero_()\n",
        "        b.grad.zero_()"
      ],
      "metadata": {
        "id": "vxmIH38HoU2I"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5j8KO_Voc6D",
        "outputId": "43b45c0e-04de-44c0-bcbc-e7c77590ebbd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4292,  0.7905,  0.8329],\n",
              "        [-0.2710,  0.8312,  0.8163]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-qmBt7rogLO",
        "outputId": "b1b3d199-de99-43b6-8180-7fd9c595d3db"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.4649, -0.7062], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs)\n",
        "loss = mse(preds, targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKzdzXvzogeP",
        "outputId": "9271d816-60c8-49d2-8dc6-2152f7e59d8a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2012, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVCAS6eQolCB",
        "outputId": "c40c381d-be13-4f72-bc54-e3adf4549272"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.9757,  70.3021],\n",
              "        [ 83.3394, 100.0217],\n",
              "        [116.4205, 134.4422],\n",
              "        [ 20.5599,  37.5970],\n",
              "        [104.1032, 117.5309]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx9Atg2OoqaV",
        "outputId": "3b4502e8-77f7-42e9-bb1a-1159cb5c9170"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# for 1000\n"
      ],
      "metadata": {
        "id": "UfclFB3Lo0GL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2NBbce6pDRh",
        "outputId": "fd7399da-f548-4c87-ca55-bafed8b3605c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4292,  0.7905,  0.8329],\n",
              "        [-0.2710,  0.8312,  0.8163]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB_u-bB2pHit",
        "outputId": "7880821a-e491-4726-934b-26815c43e841"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.4649, -0.7062], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot a graph of the number of epochs vs the loss value of the model."
      ],
      "metadata": {
        "id": "19770_xEpWbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "type(l1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLwx2_Q3pd-i",
        "outputId": "00196e3f-121b-4b03-c5d2-89900b5e8cf6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l2=np.array(range(0,1000))"
      ],
      "metadata": {
        "id": "oB_Lz2o3piRP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l1=np.array(l1)"
      ],
      "metadata": {
        "id": "G69hMNgaqCm7"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48O-S_gvqymH",
        "outputId": "55006101-28ab-4d87-d436-3ccd4e3f7ea1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2113.0884   , 1847.2708   , 1662.8353   , 1533.3093   ,\n",
              "       1440.8519   , 1373.4397   , 1322.9695   , 1283.9799   ,\n",
              "       1252.7898   , 1226.9175   , 1204.6901   , 1184.9795   ,\n",
              "       1167.0242   , 1150.3109   , 1134.4934   , 1119.3359   ,\n",
              "       1104.6808   , 1090.4197   , 1076.4797   , 1062.8107   ,\n",
              "       1049.3782   , 1036.1583   , 1023.134    , 1010.29364  ,\n",
              "        997.6287   ,  985.132    ,  972.79913  ,  960.6258   ,\n",
              "        948.6086   ,  936.745    ,  925.03186  ,  913.4676   ,\n",
              "        902.0495   ,  890.7759   ,  879.64465  ,  868.654    ,\n",
              "        857.8019   ,  847.08673  ,  836.50684  ,  826.06024  ,\n",
              "        815.7455   ,  805.5608   ,  795.5045   ,  785.575    ,\n",
              "        775.7705   ,  766.08984  ,  756.5311   ,  747.0929   ,\n",
              "        737.77374  ,  728.57196  ,  719.4862   ,  710.51495  ,\n",
              "        701.65686  ,  692.91034  ,  684.2741   ,  675.74677  ,\n",
              "        667.3268   ,  659.0129   ,  650.804    ,  642.6984   ,\n",
              "        634.6951   ,  626.7925   ,  618.9896   ,  611.285    ,\n",
              "        603.6774   ,  596.16583  ,  588.74884  ,  581.4253   ,\n",
              "        574.19403  ,  567.0541   ,  560.00385  ,  553.04254  ,\n",
              "        546.1688   ,  539.38196  ,  532.68036  ,  526.0634   ,\n",
              "        519.52966  ,  513.0783   ,  506.7082   ,  500.4184   ,\n",
              "        494.20776  ,  488.0753   ,  482.02017  ,  476.04132  ,\n",
              "        470.13776  ,  464.3086   ,  458.55283  ,  452.86945  ,\n",
              "        447.2578   ,  441.7167   ,  436.24545  ,  430.8431   ,\n",
              "        425.5087   ,  420.24164  ,  415.04083  ,  409.90552  ,\n",
              "        404.83478  ,  399.82794  ,  394.88412  ,  390.00262  ,\n",
              "        385.18256  ,  380.4231   ,  375.72357  ,  371.08325  ,\n",
              "        366.50146  ,  361.97714  ,  357.50983  ,  353.0988   ,\n",
              "        348.74326  ,  344.44247  ,  340.19586  ,  336.00275  ,\n",
              "        331.86237  ,  327.77408  ,  323.7372   ,  319.75116  ,\n",
              "        315.81528  ,  311.9289   ,  308.0915   ,  304.30225  ,\n",
              "        300.5608   ,  296.8663   ,  293.21832  ,  289.61618  ,\n",
              "        286.0594   ,  282.5474   ,  279.0796   ,  275.6553   ,\n",
              "        272.2741   ,  268.9355   ,  265.6388   ,  262.38348  ,\n",
              "        259.1693   ,  255.99544  ,  252.86137  ,  249.76689  ,\n",
              "        246.71118  ,  243.69402  ,  240.71465  ,  237.77275  ,\n",
              "        234.86792  ,  231.99951  ,  229.16719  ,  226.37051  ,\n",
              "        223.60892  ,  220.88203  ,  218.1894   ,  215.53067  ,\n",
              "        212.90523  ,  210.31279  ,  207.75305  ,  205.2253   ,\n",
              "        202.7294   ,  200.26485  ,  197.83122  ,  195.42816  ,\n",
              "        193.05533  ,  190.71223  ,  188.3986   ,  186.11397  ,\n",
              "        183.8581   ,  181.63052  ,  179.43091  ,  177.25888  ,\n",
              "        175.1141   ,  172.99629  ,  170.90506  ,  168.84004  ,\n",
              "        166.80093  ,  164.78746  ,  162.79922  ,  160.83597  ,\n",
              "        158.89725  ,  156.98288  ,  155.09254  ,  153.22598  ,\n",
              "        151.38277  ,  149.5627   ,  147.76535  ,  145.99065  ,\n",
              "        144.23817  ,  142.50764  ,  140.79887  ,  139.11148  ,\n",
              "        137.44524  ,  135.79985  ,  134.17514  ,  132.57074  ,\n",
              "        130.98648  ,  129.42207  ,  127.87716  ,  126.35172  ,\n",
              "        124.84538  ,  123.357895 ,  121.88904  ,  120.438515 ,\n",
              "        119.0062   ,  117.59184  ,  116.195145 ,  114.81594  ,\n",
              "        113.454056 ,  112.10913  ,  110.781105 ,  109.46968  ,\n",
              "        108.17464  ,  106.89581  ,  105.632996 ,  104.38595  ,\n",
              "        103.1545   ,  101.93851  ,  100.73767  ,   99.55188  ,\n",
              "         98.3809   ,   97.22455  ,   96.082634 ,   94.95503  ,\n",
              "         93.84147  ,   92.74185  ,   91.65593  ,   90.583694 ,\n",
              "         89.5247   ,   88.479    ,   87.4464   ,   86.42662  ,\n",
              "         85.419624 ,   84.425156 ,   83.44314  ,   82.47337  ,\n",
              "         81.51566  ,   80.56993  ,   79.636024 ,   78.71375  ,\n",
              "         77.80295  ,   76.90357  ,   76.015305 ,   75.13821  ,\n",
              "         74.27201  ,   73.41655  ,   72.57184  ,   71.737625 ,\n",
              "         70.91378  ,   70.100204 ,   69.29678  ,   68.50336  ,\n",
              "         67.719795 ,   66.946    ,   66.18184  ,   65.42718  ,\n",
              "         64.68192  ,   63.9459   ,   63.219074 ,   62.50127  ,\n",
              "         61.79238  ,   61.09234  ,   60.40099  ,   59.71824  ,\n",
              "         59.043922 ,   58.37803  ,   57.720387 ,   57.07093  ,\n",
              "         56.429543 ,   55.796074 ,   55.1705   ,   54.552685 ,\n",
              "         53.942505 ,   53.339947 ,   52.744865 ,   52.157127 ,\n",
              "         51.5767   ,   51.003456 ,   50.437332 ,   49.8782   ,\n",
              "         49.32601  ,   48.78064  ,   48.242073 ,   47.710117 ,\n",
              "         47.184776 ,   46.665913 ,   46.15352  ,   45.647423 ,\n",
              "         45.147594 ,   44.653942 ,   44.16638  ,   43.684853 ,\n",
              "         43.2093   ,   42.7396   ,   42.275715 ,   41.817543 ,\n",
              "         41.36504  ,   40.918114 ,   40.476685 ,   40.040756 ,\n",
              "         39.61018  ,   39.184868 ,   38.76483  ,   38.34998  ,\n",
              "         37.940228 ,   37.535534 ,   37.135796 ,   36.741024 ,\n",
              "         36.35109  ,   35.96593  ,   35.58555  ,   35.209827 ,\n",
              "         34.838703 ,   34.47216  ,   34.110115 ,   33.75251  ,\n",
              "         33.399323 ,   33.05044  ,   32.705853 ,   32.3655   ,\n",
              "         32.029293 ,   31.69725  ,   31.369247 ,   31.045246 ,\n",
              "         30.72527  ,   30.409174 ,   30.096935 ,   29.788555 ,\n",
              "         29.483923 ,   29.183002 ,   28.885763 ,   28.592184 ,\n",
              "         28.30216  ,   28.015717 ,   27.732738 ,   27.453222 ,\n",
              "         27.177113 ,   26.904377 ,   26.634945 ,   26.368814 ,\n",
              "         26.10592  ,   25.846222 ,   25.589703 ,   25.33629  ,\n",
              "         25.085957 ,   24.838688 ,   24.594393 ,   24.353102 ,\n",
              "         24.114717 ,   23.879213 ,   23.64658  ,   23.416754 ,\n",
              "         23.189734 ,   22.96546  ,   22.743896 ,   22.525    ,\n",
              "         22.308783 ,   22.09515  ,   21.884129 ,   21.675634 ,\n",
              "         21.469679 ,   21.266201 ,   21.065165 ,   20.866573 ,\n",
              "         20.67035  ,   20.476513 ,   20.284988 ,   20.095785 ,\n",
              "         19.908867 ,   19.724184 ,   19.541718 ,   19.361456 ,\n",
              "         19.183346 ,   19.007366 ,   18.833502 ,   18.661722 ,\n",
              "         18.49201  ,   18.324322 ,   18.158636 ,   17.994934 ,\n",
              "         17.83321  ,   17.673378 ,   17.515467 ,   17.359455 ,\n",
              "         17.205297 ,   17.052977 ,   16.90247  ,   16.753748 ,\n",
              "         16.606808 ,   16.4616   ,   16.31813  ,   16.176344 ,\n",
              "         16.03627  ,   15.897818 ,   15.761042 ,   15.62587  ,\n",
              "         15.492292 ,   15.360311 ,   15.229874 ,   15.100993 ,\n",
              "         14.973605 ,   14.847748 ,   14.723346 ,   14.600447 ,\n",
              "         14.478961 ,   14.3589115,   14.240278 ,   14.123032 ,\n",
              "         14.007177 ,   13.892672 ,   13.779501 ,   13.667659 ,\n",
              "         13.557118 ,   13.447879 ,   13.339899 ,   13.233215 ,\n",
              "         13.127739 ,   13.023516 ,   12.9205   ,   12.818655 ,\n",
              "         12.718027 ,   12.618546 ,   12.520215 ,   12.42304  ,\n",
              "         12.326994 ,   12.232045 ,   12.138193 ,   12.045448 ,\n",
              "         11.953748 ,   11.863111 ,   11.7735195,   11.684971 ,\n",
              "         11.59742  ,   11.510867 ,   11.425334 ,   11.340754 ,\n",
              "         11.257185 ,   11.174536 ,   11.092836 ,   11.01207  ,\n",
              "         10.932223 ,   10.853305 ,   10.775251 ,   10.698112 ,\n",
              "         10.621847 ,   10.5464325,   10.471874 ,   10.398167 ,\n",
              "         10.325286 ,   10.253228 ,   10.181989 ,   10.111545 ,\n",
              "         10.041915 ,    9.973043 ,    9.904961 ,    9.837633 ,\n",
              "          9.771075 ,    9.70523  ,    9.640144 ,    9.575789 ,\n",
              "          9.5121355,    9.449205 ,    9.386962 ,    9.325424 ,\n",
              "          9.26454  ,    9.204365 ,    9.144837 ,    9.085963 ,\n",
              "          9.027763 ,    8.97018  ,    8.913225 ,    8.85692  ,\n",
              "          8.801216 ,    8.74612  ,    8.691644 ,    8.637739 ,\n",
              "          8.584432 ,    8.531727 ,    8.479579 ,    8.428001 ,\n",
              "          8.376959 ,    8.326498 ,    8.276571 ,    8.227186 ,\n",
              "          8.178344 ,    8.130014 ,    8.082207 ,    8.034906 ,\n",
              "          7.9881325,    7.9418426,    7.896039 ,    7.850746 ,\n",
              "          7.8059263,    7.761573 ,    7.717697 ,    7.6742897,\n",
              "          7.631343 ,    7.588851 ,    7.546805 ,    7.505188 ,\n",
              "          7.4640136,    7.4232726,    7.3829675,    7.343066 ,\n",
              "          7.3036013,    7.264534 ,    7.2258735,    7.187622 ,\n",
              "          7.149751 ,    7.112281 ,    7.0752015,    7.038498 ,\n",
              "          7.0021696,    6.966211 ,    6.930627 ,    6.895415 ,\n",
              "          6.860547 ,    6.826042 ,    6.791874 ,    6.758072 ,\n",
              "          6.724593 ,    6.6914573,    6.6586637,    6.6261926,\n",
              "          6.5940466,    6.5622215,    6.5307226,    6.499514 ,\n",
              "          6.468648 ,    6.4380636,    6.4077888,    6.377807 ,\n",
              "          6.3481345,    6.318755 ,    6.2896523,    6.260828 ,\n",
              "          6.2322874,    6.204034 ,    6.176059 ,    6.1483464,\n",
              "          6.12091  ,    6.0937343,    6.066807 ,    6.0401487,\n",
              "          6.013758 ,    5.987602 ,    5.9616976,    5.9360385,\n",
              "          5.9106226,    5.8854504,    5.8605146,    5.835806 ,\n",
              "          5.811351 ,    5.7871113,    5.7630897,    5.7393017,\n",
              "          5.715731 ,    5.6923723,    5.6692343,    5.6463175,\n",
              "          5.623597 ,    5.6011024,    5.5787954,    5.5567007,\n",
              "          5.5348015,    5.5131063,    5.4915977,    5.4702973,\n",
              "          5.4491777,    5.428256 ,    5.407503 ,    5.3869405,\n",
              "          5.366563 ,    5.346377 ,    5.326352 ,    5.3065066,\n",
              "          5.2868423,    5.267358 ,    5.2480183,    5.2288632,\n",
              "          5.209878 ,    5.1910357,    5.1723814,    5.1538687,\n",
              "          5.135523 ,    5.1173353,    5.099291 ,    5.0813932,\n",
              "          5.0636706,    5.046083 ,    5.0286465,    5.011359 ,\n",
              "          4.9942083,    4.977198 ,    4.9603267,    4.9436073,\n",
              "          4.927014 ,    4.9105544,    4.8942404,    4.87805  ,\n",
              "          4.861993 ,    4.8460746,    4.8302617,    4.814594 ,\n",
              "          4.799044 ,    4.7836137,    4.768317 ,    4.7531357,\n",
              "          4.738071 ,    4.7231307,    4.70831  ,    4.693593 ,\n",
              "          4.6789956,    4.6645226,    4.650138 ,    4.6358714,\n",
              "          4.621725 ,    4.6076784,    4.593725 ,    4.5799036,\n",
              "          4.566172 ,    4.5525374,    4.539016 ,    4.525589 ,\n",
              "          4.512264 ,    4.4990377,    4.4859037,    4.472858 ,\n",
              "          4.4599185,    4.447069 ,    4.4343185,    4.421661 ,\n",
              "          4.409096 ,    4.396607 ,    4.3842206,    4.371911 ,\n",
              "          4.3596954,    4.3475647,    4.335518 ,    4.3235507,\n",
              "          4.311671 ,    4.299871 ,    4.288152 ,    4.276523 ,\n",
              "          4.2649674,    4.2534833,    4.242083 ,    4.230753 ,\n",
              "          4.2195115,    4.208332 ,    4.197232 ,    4.186198 ,\n",
              "          4.17525  ,    4.164359 ,    4.1535573,    4.14282  ,\n",
              "          4.1321445,    4.1215396,    4.111006 ,    4.1005497,\n",
              "          4.0901427,    4.079811 ,    4.0695415,    4.0593367,\n",
              "          4.0491924,    4.0391135,    4.029104 ,    4.0191503,\n",
              "          4.0092645,    3.9994235,    3.9896545,    3.9799428,\n",
              "          3.970277 ,    3.9606805,    3.9511344,    3.9416614,\n",
              "          3.9322295,    3.9228578,    3.91355  ,    3.9042823,\n",
              "          3.8950782,    3.8859267,    3.8768265,    3.8677673,\n",
              "          3.858771 ,    3.8498237,    3.8409238,    3.832079 ,\n",
              "          3.8232741,    3.8145206,    3.8058205,    3.7971706,\n",
              "          3.7885697,    3.780006 ,    3.7715015,    3.7630277,\n",
              "          3.7546146,    3.7462394,    3.7379138,    3.7296245,\n",
              "          3.7213814,    3.7131817,    3.705019 ,    3.696904 ,\n",
              "          3.6888325,    3.6808097,    3.6728148,    3.6648808,\n",
              "          3.6569676,    3.6490884,    3.6412666,    3.633475 ,\n",
              "          3.625733 ,    3.6180217,    3.6103508,    3.602715 ,\n",
              "          3.595119 ,    3.5875506,    3.5800312,    3.572538 ,\n",
              "          3.565083 ,    3.557671 ,    3.5502853,    3.5429332,\n",
              "          3.535627 ,    3.528347 ,    3.5211043,    3.5138924,\n",
              "          3.506712 ,    3.499572 ,    3.4924564,    3.4853745,\n",
              "          3.4783359,    3.4713197,    3.4643292,    3.4573808,\n",
              "          3.4504542,    3.443562 ,    3.4366963,    3.4298751,\n",
              "          3.4230747,    3.4162922,    3.409554 ,    3.402841 ,\n",
              "          3.3961544,    3.3894978,    3.3828766,    3.3762734,\n",
              "          3.3697047,    3.3631523,    3.3566337,    3.3501449,\n",
              "          3.3436794,    3.3372471,    3.3308232,    3.3244557,\n",
              "          3.318091 ,    3.3117542,    3.305442 ,    3.2991633,\n",
              "          3.2929046,    3.2866695,    3.280457 ,    3.2742767,\n",
              "          3.2681127,    3.2619758,    3.2558625,    3.2497685,\n",
              "          3.2437   ,    3.2376587,    3.2316353,    3.2256432,\n",
              "          3.219664 ,    3.2137008,    3.2077737,    3.2018707,\n",
              "          3.195979 ,    3.1901104,    3.1842752,    3.178446 ,\n",
              "          3.172648 ,    3.1668568,    3.161106 ,    3.155363 ,\n",
              "          3.1496494,    3.1439521,    3.1382709,    3.132608 ,\n",
              "          3.126968 ,    3.1213472,    3.115746 ,    3.1101766,\n",
              "          3.1046116,    3.09907  ,    3.093544 ,    3.0880387,\n",
              "          3.0825546,    3.0770829,    3.0716429,    3.0662084,\n",
              "          3.0607946,    3.0553918,    3.0500197,    3.044658 ,\n",
              "          3.0393224,    3.0339983,    3.0286942,    3.0233986,\n",
              "          3.0181234,    3.012869 ,    3.0076237,    3.0024023,\n",
              "          2.9971905,    2.9920151,    2.9868343,    2.981677 ,\n",
              "          2.9765298,    2.9714046,    2.9663062,    2.9612138,\n",
              "          2.9561336,    2.9510722,    2.9460235,    2.9409785,\n",
              "          2.935966 ,    2.9309711,    2.925981 ,    2.9210126,\n",
              "          2.9160542,    2.911106 ,    2.906196 ,    2.9012694,\n",
              "          2.8963773,    2.8914993,    2.8866234,    2.8817668,\n",
              "          2.8769286,    2.8721051,    2.867293 ,    2.86249  ,\n",
              "          2.8577   ,    2.8529365,    2.8481736,    2.8434284,\n",
              "          2.8386948,    2.8339808,    2.829276 ,    2.8245873,\n",
              "          2.8199103,    2.8152347,    2.810593 ,    2.8059473,\n",
              "          2.8013263,    2.7967026,    2.792107 ,    2.7875104,\n",
              "          2.7829382,    2.7783744,    2.773827 ,    2.769292 ,\n",
              "          2.7647483,    2.7602422,    2.755739 ,    2.7512465,\n",
              "          2.7467694,    2.7422905,    2.7378438,    2.7333894,\n",
              "          2.7289627,    2.7245426,    2.7201357,    2.715732 ,\n",
              "          2.7113502,    2.7069736,    2.7026007,    2.698256 ,\n",
              "          2.6939151,    2.6895888,    2.685266 ,    2.6809573,\n",
              "          2.6766586,    2.6723735,    2.6680868,    2.6638286,\n",
              "          2.6595738,    2.6553254,    2.651094 ,    2.646868 ,\n",
              "          2.6426575,    2.638454 ,    2.6342654,    2.6300848,\n",
              "          2.6259203,    2.6217504,    2.6175933,    2.6134543,\n",
              "          2.6093206,    2.605207 ,    2.601099 ,    2.5969894,\n",
              "          2.5929055,    2.588817 ,    2.5847561,    2.580687 ,\n",
              "          2.5766392,    2.5725913,    2.5685606,    2.5645444,\n",
              "          2.5605197,    2.556519 ,    2.552526 ,    2.548545 ,\n",
              "          2.5445747,    2.540598 ,    2.5366411,    2.532696 ,\n",
              "          2.5287557,    2.5248275,    2.5209126,    2.5170016,\n",
              "          2.5130966,    2.5092068,    2.505321 ,    2.5014527,\n",
              "          2.4975843,    2.4937272,    2.4898758,    2.4860272,\n",
              "          2.482203 ,    2.4783845,    2.4745655,    2.4707541,\n",
              "          2.4669616,    2.4631712,    2.4593961,    2.4556136,\n",
              "          2.4518566,    2.4480965,    2.4443567,    2.4406097,\n",
              "          2.4368873,    2.4331622,    2.429459 ,    2.4257476,\n",
              "          2.4220529,    2.4183655,    2.4146838,    2.4110074,\n",
              "          2.407352 ,    2.403686 ,    2.4000416,    2.396402 ,\n",
              "          2.3927665,    2.3891454,    2.3855293,    2.381919 ,\n",
              "          2.3783188,    2.3747272,    2.3711398,    2.367561 ,\n",
              "          2.3639922,    2.3604324,    2.3568819,    2.3533282,\n",
              "          2.3497913,    2.3462641,    2.342741 ,    2.3392265,\n",
              "          2.335711 ,    2.3322098,    2.3287148,    2.3252256,\n",
              "          2.321756 ,    2.3182762,    2.314815 ,    2.3113608,\n",
              "          2.3079028,    2.3044593,    2.3010228,    2.297592 ,\n",
              "          2.2941756,    2.2907624,    2.287353 ,    2.283952 ,\n",
              "          2.2805552,    2.2771742,    2.2737985,    2.270425 ,\n",
              "          2.2670567,    2.2637029,    2.2603502,    2.257007 ,\n",
              "          2.2536767,    2.2503412,    2.2470183,    2.2436986,\n",
              "          2.2403944,    2.237097 ,    2.2337985,    2.2305183,\n",
              "          2.2272272,    2.2239518,    2.2206826,    2.2174244,\n",
              "          2.2141707,    2.210923 ,    2.2076778,    2.2044458],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(l2,l1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "oVHrEScZslSZ",
        "outputId": "807e5443-7646-4699-bf02-0c34fd4aa0d3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6989de8460>]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nD1uIi7AspTS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "ecBv784Zr6Ad"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], \n",
        "                   [102, 43, 37], [69, 96, 70], [73, 67, 43], \n",
        "                   [91, 88, 64], [87, 134, 58], [102, 43, 37], \n",
        "                   [69, 96, 70], [73, 67, 43], [91, 88, 64], \n",
        "                   [87, 134, 58], [102, 43, 37], [69, 96, 70]], \n",
        "                  dtype='float32')\n",
        "\n",
        "# Targets (apples, oranges)\n",
        "targets = np.array([[56, 70], [81, 101], [119, 133], \n",
        "                    [22, 37], [103, 119], [56, 70], \n",
        "                    [81, 101], [119, 133], [22, 37], \n",
        "                    [103, 119], [56, 70], [81, 101], \n",
        "                    [119, 133], [22, 37], [103, 119]], \n",
        "                   dtype='float32')\n",
        "\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)"
      ],
      "metadata": {
        "id": "FuzFoOvVr7E0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB8s3JNnr-c0",
        "outputId": "f081eab2-f86f-4e08-f8aa-e6a3ae0c7666"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 73.,  67.,  43.],\n",
              "        [ 91.,  88.,  64.],\n",
              "        [ 87., 134.,  58.],\n",
              "        [102.,  43.,  37.],\n",
              "        [ 69.,  96.,  70.],\n",
              "        [ 73.,  67.,  43.],\n",
              "        [ 91.,  88.,  64.],\n",
              "        [ 87., 134.,  58.],\n",
              "        [102.,  43.,  37.],\n",
              "        [ 69.,  96.,  70.],\n",
              "        [ 73.,  67.,  43.],\n",
              "        [ 91.,  88.,  64.],\n",
              "        [ 87., 134.,  58.],\n",
              "        [102.,  43.,  37.],\n",
              "        [ 69.,  96.,  70.]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset"
      ],
      "metadata": {
        "id": "JO6udJDmsB56"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = TensorDataset(inputs, targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEcVcUjasEcS",
        "outputId": "0522343b-9960-4828-d6b7-a180cf784f3f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 73.,  67.,  43.],\n",
              "         [ 91.,  88.,  64.],\n",
              "         [ 87., 134.,  58.]]), tensor([[ 56.,  70.],\n",
              "         [ 81., 101.],\n",
              "         [119., 133.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Linear(3, 2)\n",
        "print(model.weight)\n",
        "print(model.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAxphHmfsHiv",
        "outputId": "83e02a42-5dc1-436a-e591-9a8906e71891"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.5491,  0.0698, -0.5244],\n",
            "        [ 0.2781,  0.5394,  0.1554]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.3743, -0.5276], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(model.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ0in-MXsT-Q",
        "outputId": "5c09dd00-0629-423d-a580-6f63248ea541"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.5491,  0.0698, -0.5244],\n",
              "         [ 0.2781,  0.5394,  0.1554]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.3743, -0.5276], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs)\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0kNaBjksXzl",
        "outputId": "5ceea957-e364-4802-c8df-1dab6f10f39f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 21.8351,  62.5984],\n",
              "        [ 22.1715,  82.1959],\n",
              "        [ 26.3300, 104.9618],\n",
              "        [ 39.2317,  56.7869],\n",
              "        [  7.5026,  81.3244],\n",
              "        [ 21.8351,  62.5984],\n",
              "        [ 22.1715,  82.1959],\n",
              "        [ 26.3300, 104.9618],\n",
              "        [ 39.2317,  56.7869],\n",
              "        [  7.5026,  81.3244],\n",
              "        [ 21.8351,  62.5984],\n",
              "        [ 22.1715,  82.1959],\n",
              "        [ 26.3300, 104.9618],\n",
              "        [ 39.2317,  56.7869],\n",
              "        [  7.5026,  81.3244]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "loss_fn = F.mse_loss\n",
        "loss = loss_fn(model(inputs), targets)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooQhrv20sadk",
        "outputId": "68e1ca74-a766-4af7-f827-d96fe1364052"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2563.7952, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "P4JEUwN-sjdF"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
        "    \n",
        "    # Repeat for given number of epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        # Train with batches of data\n",
        "        for xb,yb in train_dl:\n",
        "            \n",
        "            # 1. Generate predictions\n",
        "            pred = model(xb)\n",
        "            \n",
        "            # 2. Calculate loss\n",
        "            loss = loss_fn(pred, yb)\n",
        "            \n",
        "            # 3. Compute gradients\n",
        "            loss.backward()\n",
        "            \n",
        "            # 4. Update parameters using gradients\n",
        "            opt.step()\n",
        "            \n",
        "            # 5. Reset the gradients to zero\n",
        "            opt.zero_grad()\n",
        "        \n",
        "        # Print the progress\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
      ],
      "metadata": {
        "id": "EFhmaeJzstzu"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit(100, model, loss_fn, opt, train_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sjJ3xShs4U8",
        "outputId": "1f2c3a64-8204-4f7a-eb10-b590ca831fa0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 422.9674\n",
            "Epoch [20/100], Loss: 385.9197\n",
            "Epoch [30/100], Loss: 275.4437\n",
            "Epoch [40/100], Loss: 340.1692\n",
            "Epoch [50/100], Loss: 186.8352\n",
            "Epoch [60/100], Loss: 126.9953\n",
            "Epoch [70/100], Loss: 139.0142\n",
            "Epoch [80/100], Loss: 51.7845\n",
            "Epoch [90/100], Loss: 66.9167\n",
            "Epoch [100/100], Loss: 57.4484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 5\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "for xb, yb in train_dl:\n",
        "    print(xb)\n",
        "    print(yb)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5Dahmcqs8X-",
        "outputId": "28bffd7c-7be0-4eb3-f204-3f9de6a53bc8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 91.,  88.,  64.],\n",
            "        [ 69.,  96.,  70.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [102.,  43.,  37.]])\n",
            "tensor([[ 81., 101.],\n",
            "        [103., 119.],\n",
            "        [ 81., 101.],\n",
            "        [ 81., 101.],\n",
            "        [ 22.,  37.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mino = []"
      ],
      "metadata": {
        "id": "EK23NSmGtRVe"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mino= fit(1000, model, loss_fn, opt, train_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBW5RF35tbPK",
        "outputId": "201576dd-f103-44fe-ceec-d8237614432e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/1000], Loss: 71.0997\n",
            "Epoch [20/1000], Loss: 53.5428\n",
            "Epoch [30/1000], Loss: 46.3899\n",
            "Epoch [40/1000], Loss: 30.9717\n",
            "Epoch [50/1000], Loss: 53.2324\n",
            "Epoch [60/1000], Loss: 49.0318\n",
            "Epoch [70/1000], Loss: 38.9226\n",
            "Epoch [80/1000], Loss: 45.4361\n",
            "Epoch [90/1000], Loss: 15.4119\n",
            "Epoch [100/1000], Loss: 22.8039\n",
            "Epoch [110/1000], Loss: 42.3402\n",
            "Epoch [120/1000], Loss: 39.1673\n",
            "Epoch [130/1000], Loss: 14.8743\n",
            "Epoch [140/1000], Loss: 37.9936\n",
            "Epoch [150/1000], Loss: 3.0158\n",
            "Epoch [160/1000], Loss: 2.8227\n",
            "Epoch [170/1000], Loss: 8.9895\n",
            "Epoch [180/1000], Loss: 15.5542\n",
            "Epoch [190/1000], Loss: 8.0905\n",
            "Epoch [200/1000], Loss: 14.0296\n",
            "Epoch [210/1000], Loss: 11.2939\n",
            "Epoch [220/1000], Loss: 23.0082\n",
            "Epoch [230/1000], Loss: 16.6584\n",
            "Epoch [240/1000], Loss: 20.6492\n",
            "Epoch [250/1000], Loss: 14.7556\n",
            "Epoch [260/1000], Loss: 8.4735\n",
            "Epoch [270/1000], Loss: 13.5907\n",
            "Epoch [280/1000], Loss: 8.7787\n",
            "Epoch [290/1000], Loss: 13.5855\n",
            "Epoch [300/1000], Loss: 7.8194\n",
            "Epoch [310/1000], Loss: 8.1459\n",
            "Epoch [320/1000], Loss: 7.3408\n",
            "Epoch [330/1000], Loss: 6.6721\n",
            "Epoch [340/1000], Loss: 6.4364\n",
            "Epoch [350/1000], Loss: 6.2148\n",
            "Epoch [360/1000], Loss: 5.7867\n",
            "Epoch [370/1000], Loss: 5.4557\n",
            "Epoch [380/1000], Loss: 8.2010\n",
            "Epoch [390/1000], Loss: 5.0385\n",
            "Epoch [400/1000], Loss: 7.3882\n",
            "Epoch [410/1000], Loss: 3.3426\n",
            "Epoch [420/1000], Loss: 4.3734\n",
            "Epoch [430/1000], Loss: 8.4961\n",
            "Epoch [440/1000], Loss: 1.7521\n",
            "Epoch [450/1000], Loss: 5.3863\n",
            "Epoch [460/1000], Loss: 3.4831\n",
            "Epoch [470/1000], Loss: 3.4152\n",
            "Epoch [480/1000], Loss: 3.2541\n",
            "Epoch [490/1000], Loss: 3.0047\n",
            "Epoch [500/1000], Loss: 1.6141\n",
            "Epoch [510/1000], Loss: 2.9578\n",
            "Epoch [520/1000], Loss: 4.2574\n",
            "Epoch [530/1000], Loss: 2.4494\n",
            "Epoch [540/1000], Loss: 1.1651\n",
            "Epoch [550/1000], Loss: 2.3504\n",
            "Epoch [560/1000], Loss: 2.1122\n",
            "Epoch [570/1000], Loss: 2.1508\n",
            "Epoch [580/1000], Loss: 2.0599\n",
            "Epoch [590/1000], Loss: 1.9738\n",
            "Epoch [600/1000], Loss: 0.9360\n",
            "Epoch [610/1000], Loss: 1.7692\n",
            "Epoch [620/1000], Loss: 0.9381\n",
            "Epoch [630/1000], Loss: 0.8103\n",
            "Epoch [640/1000], Loss: 1.3912\n",
            "Epoch [650/1000], Loss: 0.6872\n",
            "Epoch [660/1000], Loss: 1.4337\n",
            "Epoch [670/1000], Loss: 0.3681\n",
            "Epoch [680/1000], Loss: 1.2528\n",
            "Epoch [690/1000], Loss: 2.0818\n",
            "Epoch [700/1000], Loss: 1.9952\n",
            "Epoch [710/1000], Loss: 1.1394\n",
            "Epoch [720/1000], Loss: 1.0851\n",
            "Epoch [730/1000], Loss: 1.1660\n",
            "Epoch [740/1000], Loss: 0.9453\n",
            "Epoch [750/1000], Loss: 1.6792\n",
            "Epoch [760/1000], Loss: 1.0117\n",
            "Epoch [770/1000], Loss: 0.5245\n",
            "Epoch [780/1000], Loss: 0.9157\n",
            "Epoch [790/1000], Loss: 1.4910\n",
            "Epoch [800/1000], Loss: 0.9481\n",
            "Epoch [810/1000], Loss: 0.4170\n",
            "Epoch [820/1000], Loss: 0.8998\n",
            "Epoch [830/1000], Loss: 1.3024\n",
            "Epoch [840/1000], Loss: 1.2999\n",
            "Epoch [850/1000], Loss: 0.6096\n",
            "Epoch [860/1000], Loss: 0.8852\n",
            "Epoch [870/1000], Loss: 0.7518\n",
            "Epoch [880/1000], Loss: 0.4331\n",
            "Epoch [890/1000], Loss: 0.7031\n",
            "Epoch [900/1000], Loss: 0.5431\n",
            "Epoch [910/1000], Loss: 0.7405\n",
            "Epoch [920/1000], Loss: 0.4381\n",
            "Epoch [930/1000], Loss: 1.0600\n",
            "Epoch [940/1000], Loss: 0.6425\n",
            "Epoch [950/1000], Loss: 0.4872\n",
            "Epoch [960/1000], Loss: 0.6531\n",
            "Epoch [970/1000], Loss: 0.5927\n",
            "Epoch [980/1000], Loss: 0.6385\n",
            "Epoch [990/1000], Loss: 0.4108\n",
            "Epoch [1000/1000], Loss: 0.9521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs)\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV4lcYO6tgZ4",
        "outputId": "329f19b4-b43c-4af8-8362-7e321fe4eb74"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 57.1696,  70.2563],\n",
              "        [ 81.9777, 100.5225],\n",
              "        [119.3942, 133.4361],\n",
              "        [ 21.2991,  37.1644],\n",
              "        [101.3072, 118.6856],\n",
              "        [ 57.1696,  70.2563],\n",
              "        [ 81.9777, 100.5225],\n",
              "        [119.3942, 133.4361],\n",
              "        [ 21.2991,  37.1644],\n",
              "        [101.3072, 118.6856],\n",
              "        [ 57.1696,  70.2563],\n",
              "        [ 81.9777, 100.5225],\n",
              "        [119.3942, 133.4361],\n",
              "        [ 21.2991,  37.1644],\n",
              "        [101.3072, 118.6856]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3W8w9vQtjSr",
        "outputId": "f3389275-2ecc-49e8-ebf2-fd41376ec3c0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.],\n",
              "        [ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.],\n",
              "        [ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q-CpnVjetmfZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}